{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "PySpark_J049_J052.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6hqIj-w-iiD"
      },
      "source": [
        "**Jayesh Singh J049**<BR>\n",
        "**Shankh Suri J052**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYc5Ale8uthc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eaeebef-db88-490f-836f-dfcf8a57ced8"
      },
      "source": [
        " !pip install pyspark \n",
        " !pip install findspark"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n",
            "\u001b[K     |████████████████████████████████| 212.3MB 72kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 49.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=aadf97e93b984b1aebf839ab9f5bfc4443aaa8d17e365c2ffb27fb50600b58e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.1\n",
            "Collecting findspark\n",
            "  Downloading https://files.pythonhosted.org/packages/fc/2d/2e39f9a023479ea798eed4351cd66f163ce61e00c717e03c37109f00c0f2/findspark-1.4.2-py2.py3-none-any.whl\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QdAx3F_muIG"
      },
      "source": [
        "import findspark\n",
        "# findspark.init()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo1YJZGAmuIM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afaefd75-ad23-4f70-fc7c-6760fe39f520"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "df = spark.sql(\"select 'spark' as hello\")\n",
        "df.show()\n",
        "spark.stop()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|hello|\n",
            "+-----+\n",
            "|spark|\n",
            "+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjpROz-SmuIN"
      },
      "source": [
        "# pyspark.SparkContext (\n",
        "#    master = None,\n",
        "#    appName = None, \n",
        "#    sparkHome = None, \n",
        "#    pyFiles = None, \n",
        "#    environment = None, \n",
        "#    batchSize = 0, \n",
        "#    serializer = PickleSerializer(), \n",
        "#    conf = None, \n",
        "#    gateway = None, \n",
        "#    jsc = None, \n",
        "#   #  profiler_cls = <class 'pyspark.profiler.BasicProfiler'>\n",
        "#   profiler_cls = 'pyspark.profiler.BasicProfiler'\n",
        "# )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3HjUXoPmuIO"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "sc = SparkContext('local', 'test_1')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCV4qmVjmuIO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "8d8c49da-b07b-4551-db71-8d9dc0bab255"
      },
      "source": [
        "sc"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://c3fa3cb31b79:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>test_1</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        "
            ],
            "text/plain": [
              "<SparkContext master=local appName=test_1>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiX79dermuIO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f890ee6-03a2-4117-fe51-411feb62dc2b"
      },
      "source": [
        "x= ['Python', 'is', 'really', 'conveniant','Colab','is','very','fast']\n",
        "print(sorted(x))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Colab', 'Python', 'conveniant', 'fast', 'is', 'is', 'really', 'very']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6puoXq1muIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23d9b06-4896-4d55-a6b5-16cffc90c389"
      },
      "source": [
        "sorted(x, key = lambda arg : arg.lower())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Colab', 'conveniant', 'fast', 'is', 'is', 'Python', 'really', 'very']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gozUaqe9muIP"
      },
      "source": [
        "## filter()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3pP7GdUmuIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2e1d175-8a72-4e3c-b128-b084b252c155"
      },
      "source": [
        "list(filter(lambda arg: len(arg) < 5, x))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['is', 'is', 'very', 'fast']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jgk8UW-muIP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee29d3c-9e6e-42e9-d8ac-5162a33c0b6f"
      },
      "source": [
        "def check_length(x):\n",
        "    return len(x)<5\n",
        "\n",
        "l1=[]\n",
        "\n",
        "for i in x:\n",
        "    if check_length(i):\n",
        "        l1.append(i)\n",
        "        \n",
        "print(l1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['is', 'is', 'very', 'fast']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67sIq02pmuIQ"
      },
      "source": [
        "## map()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbKoYUcfmuIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3caf654-bfeb-42bc-c9f9-e3d894ca349c"
      },
      "source": [
        "print(list(map(lambda arg : check_length(arg), x)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, False, False, False, True, True, True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3zcAO9HmuIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1f04f7e-91b8-4b2c-b2de-c52f155b9f64"
      },
      "source": [
        "def check_length(x):\n",
        "    return len(x)<5\n",
        "\n",
        "l1=[]\n",
        "\n",
        "for i in x:\n",
        "    l1.append(check_length(i))\n",
        "        \n",
        "print(l1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, True, False, False, False, True, True, True]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7F2PukzmuIR"
      },
      "source": [
        "## reduce()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHWzhwiimuIR"
      },
      "source": [
        "def concat(x,y):\n",
        "    print( f'{x} + {y} = {x+y}')\n",
        "    return x + y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZcWaajamuIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a973565-1406-46c0-a17c-0e4162f53833"
      },
      "source": [
        "from functools import reduce\n",
        "print(reduce(lambda i,j: concat(i,j), x))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python + is = Pythonis\n",
            "Pythonis + really = Pythonisreally\n",
            "Pythonisreally + conveniant = Pythonisreallyconveniant\n",
            "Pythonisreallyconveniant + Colab = PythonisreallyconveniantColab\n",
            "PythonisreallyconveniantColab + is = PythonisreallyconveniantColabis\n",
            "PythonisreallyconveniantColabis + very = PythonisreallyconveniantColabisvery\n",
            "PythonisreallyconveniantColabisvery + fast = PythonisreallyconveniantColabisveryfast\n",
            "PythonisreallyconveniantColabisveryfast\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARo_EVKPmuIR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f47cba1e-8d8e-4355-bdf7-b571da498f5d"
      },
      "source": [
        "print(reduce(lambda i,j: concat(i,j), range(10)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 + 1 = 1\n",
            "1 + 2 = 3\n",
            "3 + 3 = 6\n",
            "6 + 4 = 10\n",
            "10 + 5 = 15\n",
            "15 + 6 = 21\n",
            "21 + 7 = 28\n",
            "28 + 8 = 36\n",
            "36 + 9 = 45\n",
            "45\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fl0xeq7smuIS"
      },
      "source": [
        "## PySpark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGMo4gs2yfor"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7wBSYSKmuIS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b800ff63-690a-425c-c07e-f887f3d76d66"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pyspark\n",
        "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
        "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
        "sc = pyspark.SparkContext('local[*]')\n",
        "os.getcwd()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-ciCnK0muIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7644df6-e511-4991-b531-1279a7eabeed"
      },
      "source": [
        "txt = sc.textFile('/content/pyspark1.txt')\n",
        "print(txt.count())\n",
        "\n",
        "python_lines = txt.filter(lambda line: 'spark' in line.lower())\n",
        "print(python_lines.count())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_2yrDfsmuIS"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we_HxLjsmuIT"
      },
      "source": [
        "## RDD Resilient Distributed Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNWzUX75muIT"
      },
      "source": [
        "sc = pyspark.SparkContext('local[*]')\n",
        "\n",
        "words = sc.parallelize(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])\n",
        "\n",
        "words.count()\n",
        "\n",
        "words.collect()\n",
        "\n",
        "def test(x):\n",
        "    print(x)\n",
        "\n",
        "test_result = words.foreach(test)\n",
        "sc.stop()\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-TfdxUsmuIT"
      },
      "source": [
        "sc = pyspark.SparkContext('local[*]', 'cache check')\n",
        "\n",
        "words = sc.parallelize(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQP5PWk5muIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "753d07f4-d73d-4053-c224-f8f07ca20c71"
      },
      "source": [
        "words.persist().is_cached"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H_ybt5SmuIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1868515-a8e8-4a06-a3f6-010a596f5820"
      },
      "source": [
        "words.cache()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ev6G1C0muIU"
      },
      "source": [
        "## Shared Variables\n",
        "\n",
        "* Broadcast\n",
        "* Accumulator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCpFCJRImuIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b28e3e12-c0c2-46b1-b7b8-559b4400d12d"
      },
      "source": [
        "words_2 = sc.broadcast(['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris'])\n",
        "data = words_2.value\n",
        "print(f'Stored data is {data}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stored data is ['scala', 'mahout', 'solaris', 'vertica', 'reddis', 'hadoop', 'lunaris']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9i-nft3muIU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7749df6c-6029-4bb2-ddcd-196af3bffa22"
      },
      "source": [
        "words_2.value[2]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'solaris'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLgQejwKmuIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e815580b-36f8-482c-d59b-ab7f73331440"
      },
      "source": [
        "y = sc.accumulator(100)\n",
        "def f(x):\n",
        "    global y\n",
        "    y+=x\n",
        "    \n",
        "rdd = sc.parallelize([10,20,30,40,50])\n",
        "rdd.foreach(f)\n",
        "\n",
        "final = y.value\n",
        "print(final)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWx22ZUzmuIU"
      },
      "source": [
        "sc.stop()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX10mLeKmuIV"
      },
      "source": [
        "## Spark mllib\n",
        "\n",
        "* classification\n",
        "* regression\n",
        "* clustering\n",
        "* linalg\n",
        "* recommendation\n",
        "* fpm"
      ]
    }
  ]
}